data <- read.csv(temp, na.strings = nastrings)
unlink(temp)
return(data)
}
trainurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
train <- downloadcsv(trainurl, c("", "NA", "#DIV/0!"))
trainurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
train <- downloadcsv(trainurl, c("", "NA", "#DIV/0!"))
train <- downloadcsv(trainurl, c("", "NA", "#DIV/0!"))
?read.csv()
train <- read.csv("E:\pml-training", na.strings = nastrings)
train <- read.csv("E:/pml-training", na.strings = nastrings)
pml.training <- read.csv("E:/pml-training.csv")
View(pml.training)
pml.testing <- read.csv("E:/pml-testing.csv")
View(pml.testing)
train <-pml-training
train <-pml.training
test<-pml.testing
set.seed(123456)
trainset <- createDataPartition(train$classe, p = 0.8, list = FALSE)
Training <- train[trainset, ]
Validation <- train[-trainset, ]
View(Training)
downloadcsv <- function(url, nastrings) {
temp <- tempfile()
download.file(url, temp, method = "curl")
data <- read.csv(temp, na.strings = nastrings)
unlink(temp)
return(data)
}
trainurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
train <- downloadcsv(trainurl, c("", "NA", "#DIV/0!"))
?sapply()
nzvcol <- nearZeroVar(Training)
Training <- Training[, -nzvcol]
cntlength <- sapply(Training, function(x) {
sum(!(is.na(x) | x == ""))
})
View(cntlength)
nullcol <- names(cntlength[cntlength < 0.6 * length(Training$classe)])
View(nullcol)
View(names(cntlength[1]))
View(names(cntlength[0]))
library(randomForest)
install.packages("randomForest")
library(randomForest)
rfModel <- randomForest(classe ~ ., data = Training, importance = TRUE, ntrees = 10)
nullcol <- names(cntlength[cntlength < 0.6 * length(Training$classe)])
descriptcol <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2",
"cvtd_timestamp", "new_window", "num_window")
excludecols <- c(descriptcol, nullcol)
Training <- Training[, !names(Training) %in% excludecols]
library(randomForest)
rfModel <- randomForest(classe ~ ., data = Training, importance = TRUE, ntrees = 10)
ptraining <- predict(rfModel, Training)
print(confusionMatrix(ptraining, Training$classe))
pvalidation <- predict(rfModel, Validation)
print(confusionMatrix(pvalidation, Validation$classe))
ptest <- predict(rfModel, test)
ptest
answers <- as.vector(ptest)
pml_write_files = function(x) {
n = length(x)
for (i in 1:n) {
filename = paste0("problem_id_", i, ".txt")
write.table(x[i], file = filename, quote = FALSE, row.names = FALSE,
col.names = FALSE)
}
}
?paste()
predictionassignmet()
library(caret)
library(parallel)
library(doParallel)
loadData<-function(){
#remove variables
#rm(list = ls())
#load raw data
training <<- read.csv("pml-training.csv", header = TRUE)
test  <<- read.csv('pml-testing.csv')
}
cleanData<-function(){
#remove columns with over a 90% of not a number
nasPerColumn<<- apply(training,2,function(x) {sum(is.na(x))});
training <<- training[,which(nasPerColumn <  nrow(training)*0.9)];
#remove near zero variance predictors
nearZeroColumns <<- nearZeroVar(training, saveMetrics = TRUE)
training <<- training[, nearZeroColumns$nzv==FALSE]
#remove not relevant columns for classification (x, user_name, raw time stamp 1  and 2, "new_window" and "num_window")
training<<-training[,7:ncol(training)]
#class into factor
training$classe <<- factor(training$classe)
}
#split training in 60% training and 40% test
splitdata<-function(){
trainIndex <<- createDataPartition(y = training$classe, p=0.6,list=FALSE);
trainingPartition <<- training[trainIndex,];
testingPartition <<- training[-trainIndex,];
}
fitmodel<-function(){
#random seed
set.seed(3433)
#parallel computing for multi-core
registerDoParallel(makeCluster(detectCores()))
#three models are generated:  random forest   ("rf"), boosted trees ("gbm") and linear discriminant analysis ("lda") model
model_rf <<- train(classe ~ .,  method="rf", data=trainingPartition)
model_gbm <<-train(classe ~ ., method = 'gbm', data = trainingPartition)
model_lda <<-train(classe ~ ., method = 'lda', data = trainingPartition)
}
#accuracy info for testingPartition (testing)
accuracyInfo<-function(){
print("Random forest accuracy ")
rf_accuracy<<- predict(model_rf, testingPartition)
print(confusionMatrix(rf_accuracy, testingPartition$classe))
print("")
print("Boosted trees accuracy ")
gbm_accuracy<<- predict(model_gbm , testingPartition)
print(confusionMatrix(gbm_accuracy, testingPartition$classe))
print("")
print("Linear discriminant analysis")
lda_accuracy<<- predict(model_lda , testingPartition)
print()
print(confusionMatrix(lda_accuracy, testingPartition$classe))
}
#tuning the random forest model with CV
CVTuning<-function(){
#random seed
set.seed(3433)
#parallel computing for multi-core
registerDoParallel(makeCluster(detectCores()))
controlf <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
model_rf_CV <<- train(classe ~ ., method="rf",  data=trainingPartition, trControl = controlf)
print("Random forest accuracy after CV")
rf_CV_accuracy<<- predict(model_rf_CV , testingPartition)
print(confusionMatrix(rf_CV_accuracy, testingPartition$classe))
}
#get the most important variables in the model
mostImportantVariables<-function(){
print("Variables importance in model")
vi = varImp(model_rf_CV$finalModel)
vi$var<-rownames(vi)
vi = as.data.frame(vi[with(vi, order(vi$Overall, decreasing=TRUE)), ])
rownames(vi) <- NULL
print(vi)
}
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
#Prediction Assignment Submission
predictionassignmet<- function(){
prediction <- predict(model_rf_CV, test)
print(prediction)
answers <- as.vector(prediction)
pml_write_files(answers)
}
loadData()
cleanData()
splitdata()
fitmodel()
accuracyInfo()
CVTuning()
mostImportantVariables()
predictionassignmet()
trainurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train<- read.csv(text=getURL(trainurl), na.strings=c("", "NA"))
install.packages("RCurl")
library(RCurl)
trainurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train<- read.csv(text=getURL(trainurl), na.strings=c("", "NA"))
library(RCurl)
trainurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train<- read.csv(text=getURL(trainurl), na.strings=c("", "NA"))
library(RCurl)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_data <- read.csv(text=getURL(train_url), na.strings=c("", "NA"))
test_data <- read.csv(text=getURL(test_url), na.strings=c("", "NA"))
v<-c()
View(v)
pml.training <- read.csv("E:/pml-training.csv")
View(pml.training)
pml.testing <- read.csv("E:/pml-testing.csv")
View(pml.testing)
train <-pml.training
test<-pml.testing
train_data<-pml.training
test_data<-pml.testing
train_data$X <- NULL
cols_to_remove <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp")
for (col in cols_to_remove) {
train_data[, col] <- NULL
}
NAs <- apply(train_data,2,function(x) {sum(is.na(x))})
train_data <- train_data[,which(NAs == 0)]
library(caret)
NAs <- apply(train_data,2,function(x) {sum(is.na(x))})
train_data <- train_data[,which(NAs == 0)]
nsv <- nearZeroVar(train_data)
train_data <- train_data[-nsv]
test_data <- test_data[-nsv]
names(train_data)
library(randomForest)
set.seed(1)
obs <- c()
preds <- c()
for(i in 1:10) {
intrain = sample(1:dim(train_data)[1], size=dim(train_data)[1] * 0.8, replace=F)
train_cross = train_data[intrain,]
test_cross = train_data[-intrain,]
rf <- randomForest(classe ~ ., data=train_cross)
obs <- c(obs, test_cross$classe)
preds <- c(preds, predict(rf, test_cross))
}
View(obs)
obs <- c()
preds <- c()
for(i in 1:10) {
intrain = sample(1:dim(train_data)[1], size=dim(train_data)[1] * 0.8, replace=F)
train_cross = train_data[intrain,]
test_cross = train_data[-intrain,]
rf <- randomForest(classe ~ ., data=train_cross)
obs <- c(obs, test_cross$classe)
preds <- c(preds, predict(rf, test_cross))
}
install.packages("evaluate")
library(evaluate)
install.packages("formatR")
library(formatR)
load("rf_model.RData", verbose=TRUE)
train_data<-pml.training
test_data<-pml.testing
## ----cache=TRUE----------------------------------------------------------
library(RCurl)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_data <- read.csv(text=getURL(train_url), na.strings=c("", "NA"))
test_data <- read.csv(text=getURL(test_url), na.strings=c("", "NA"))
train_data<-pml.training
test_data<-pml.testing
## ------------------------------------------------------------------------
train_data$X <- NULL
## ------------------------------------------------------------------------
cols_to_remove <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp")
for (col in cols_to_remove) {
train_data[, col] <- NULL
}
## ------------------------------------------------------------------------
NAs <- apply(train_data,2,function(x) {sum(is.na(x))})
train_data <- train_data[,which(NAs == 0)]
## ----message=FALSE-------------------------------------------------------
library(caret)
nsv <- nearZeroVar(train_data)
train_data <- train_data[-nsv]
test_data <- test_data[-nsv]
## ------------------------------------------------------------------------
names(train_data)
## ----cache=TRUE----------------------------------------------------------
library(randomForest)
set.seed(1)
obs <- c()
preds <- c()
for(i in 1:10) {
intrain = sample(1:dim(train_data)[1], size=dim(train_data)[1] * 0.8, replace=F)
train_cross = train_data[intrain,]
test_cross = train_data[-intrain,]
rf <- randomForest(classe ~ ., data=train_cross)
obs <- c(obs, test_cross$classe)
preds <- c(preds, predict(rf, test_cross))
}
rf <- randomForest(classe ~ ., data=train_cross)
load("rf_model.RData", verbose=TRUE)
install.packages("knitr")
library(knitr)
train_data<-pml.training
test_data<-pml.testing
train_data$X <- NULL
cols_to_remove <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp")
for (col in cols_to_remove) {
train_data[, col] <- NULL
}
NAs <- apply(train_data,2,function(x) {sum(is.na(x))})
train_data <- train_data[,which(NAs == 0)]
library(caret)
nsv <- nearZeroVar(train_data)
train_data <- train_data[-nsv]
test_data <- test_data[-nsv]
names(train_data)
library(randomForest)
set.seed(1)
obs <- c()
preds <- c()
intrain = sample(1:dim(train_data)[1], size=dim(train_data)[1] * 0.8, replace=F)
train_cross = train_data[intrain,]
test_cross = train_data[-intrain,]
rf <- randomForest(classe ~ ., data=train_cross)
obs <- c(obs, test_cross$classe)
preds <- c(preds, predict(rf, test_cross))
View(obs)
conf_mat <- confusionMatrix(table(preds, obs))
model <- randomForest(classe ~ ., data=train_data)
load("rf_model.RData", verbose=TRUE)
?load()
load("model", verbose=TRUE)
training <<- training[,which(nasPerColumn <  nrow(training)*0.9)];
training <<- read.csv("pml-training.csv", header = TRUE)
setwd("E:/GitBash/ML_project")
training <<- read.csv("pml-training.csv", header = TRUE)
training <<- read.csv("pml-training.csv", header = TRUE)
library(caret)
library(parallel)
library(doParallel)
loadData<-function(){
#remove variables
#rm(list = ls())
#load raw data
training <<- read.csv("pml-training.csv", header = TRUE)
test  <<- read.csv('pml-testing.csv')
}
cleanData<-function(){
#remove columns with over a 90% of not a number
nasPerColumn<<- apply(training,2,function(x) {sum(is.na(x))});
training <<- training[,which(nasPerColumn <  nrow(training)*0.9)];
#remove near zero variance predictors
nearZeroColumns <<- nearZeroVar(training, saveMetrics = TRUE)
training <<- training[, nearZeroColumns$nzv==FALSE]
#remove not relevant columns for classification (x, user_name, raw time stamp 1  and 2, "new_window" and "num_window")
training<<-training[,7:ncol(training)]
#class into factor
training$classe <<- factor(training$classe)
}
#split training in 60% training and 40% test
splitdata<-function(){
trainIndex <<- createDataPartition(y = training$classe, p=0.6,list=FALSE);
trainingPartition <<- training[trainIndex,];
testingPartition <<- training[-trainIndex,];
}
fitmodel<-function(){
#random seed
set.seed(3433)
#parallel computing for multi-core
registerDoParallel(makeCluster(detectCores()))
#three models are generated:  random forest   ("rf"), boosted trees ("gbm") and linear discriminant analysis ("lda") model
model_rf <<- train(classe ~ .,  method="rf", data=trainingPartition)
model_gbm <<-train(classe ~ ., method = 'gbm', data = trainingPartition)
model_lda <<-train(classe ~ ., method = 'lda', data = trainingPartition)
}
#accuracy info for testingPartition (testing)
accuracyInfo<-function(){
print("Random forest accuracy ")
rf_accuracy<<- predict(model_rf, testingPartition)
print(confusionMatrix(rf_accuracy, testingPartition$classe))
print("")
print("Boosted trees accuracy ")
gbm_accuracy<<- predict(model_gbm , testingPartition)
print(confusionMatrix(gbm_accuracy, testingPartition$classe))
print("")
print("Linear discriminant analysis")
lda_accuracy<<- predict(model_lda , testingPartition)
print()
print(confusionMatrix(lda_accuracy, testingPartition$classe))
}
#tuning the random forest model with CV
CVTuning<-function(){
#random seed
set.seed(3433)
#parallel computing for multi-core
registerDoParallel(makeCluster(detectCores()))
controlf <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
model_rf_CV <<- train(classe ~ ., method="rf",  data=trainingPartition, trControl = controlf)
print("Random forest accuracy after CV")
rf_CV_accuracy<<- predict(model_rf_CV , testingPartition)
print(confusionMatrix(rf_CV_accuracy, testingPartition$classe))
}
#get the most important variables in the model
mostImportantVariables<-function(){
print("Variables importance in model")
vi = varImp(model_rf_CV$finalModel)
vi$var<-rownames(vi)
vi = as.data.frame(vi[with(vi, order(vi$Overall, decreasing=TRUE)), ])
rownames(vi) <- NULL
print(vi)
}
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
#Prediction Assignment Submission
predictionassignmet<- function(){
prediction <- predict(model_rf_CV, test)
print(prediction)
answers <- as.vector(prediction)
pml_write_files(answers)
}
loadData()
cleanData()
splitdata()
fitmodel()
accuracyInfo()
CVTuning()
mostImportantVariables()
predictionassignmet()
library(doParallel)
install.packages("doParallel")
library(doParallel)
library(parallel)
library(doParallel)
library(caret)
library(parallel)
library(doParallel)
loadData<-function(){
#remove variables
#rm(list = ls())
#load raw data
training <<- read.csv("pml-training.csv", header = TRUE)
test  <<- read.csv('pml-testing.csv')
}
cleanData<-function(){
#remove columns with over a 90% of not a number
nasPerColumn<<- apply(training,2,function(x) {sum(is.na(x))});
training <<- training[,which(nasPerColumn <  nrow(training)*0.9)];
#remove near zero variance predictors
nearZeroColumns <<- nearZeroVar(training, saveMetrics = TRUE)
training <<- training[, nearZeroColumns$nzv==FALSE]
#remove not relevant columns for classification (x, user_name, raw time stamp 1  and 2, "new_window" and "num_window")
training<<-training[,7:ncol(training)]
#class into factor
training$classe <<- factor(training$classe)
}
#split training in 60% training and 40% test
splitdata<-function(){
trainIndex <<- createDataPartition(y = training$classe, p=0.6,list=FALSE);
trainingPartition <<- training[trainIndex,];
testingPartition <<- training[-trainIndex,];
}
fitmodel<-function(){
#random seed
set.seed(3433)
#parallel computing for multi-core
registerDoParallel(makeCluster(detectCores()))
#three models are generated:  random forest   ("rf"), boosted trees ("gbm") and linear discriminant analysis ("lda") model
model_rf <<- train(classe ~ .,  method="rf", data=trainingPartition)
model_gbm <<-train(classe ~ ., method = 'gbm', data = trainingPartition)
model_lda <<-train(classe ~ ., method = 'lda', data = trainingPartition)
}
#accuracy info for testingPartition (testing)
accuracyInfo<-function(){
print("Random forest accuracy ")
rf_accuracy<<- predict(model_rf, testingPartition)
print(confusionMatrix(rf_accuracy, testingPartition$classe))
print("")
print("Boosted trees accuracy ")
gbm_accuracy<<- predict(model_gbm , testingPartition)
print(confusionMatrix(gbm_accuracy, testingPartition$classe))
print("")
print("Linear discriminant analysis")
lda_accuracy<<- predict(model_lda , testingPartition)
print()
print(confusionMatrix(lda_accuracy, testingPartition$classe))
}
#tuning the random forest model with CV
CVTuning<-function(){
#random seed
set.seed(3433)
#parallel computing for multi-core
registerDoParallel(makeCluster(detectCores()))
controlf <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
model_rf_CV <<- train(classe ~ ., method="rf",  data=trainingPartition, trControl = controlf)
print("Random forest accuracy after CV")
rf_CV_accuracy<<- predict(model_rf_CV , testingPartition)
print(confusionMatrix(rf_CV_accuracy, testingPartition$classe))
}
#get the most important variables in the model
mostImportantVariables<-function(){
print("Variables importance in model")
vi = varImp(model_rf_CV$finalModel)
vi$var<-rownames(vi)
vi = as.data.frame(vi[with(vi, order(vi$Overall, decreasing=TRUE)), ])
rownames(vi) <- NULL
print(vi)
}
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
#Prediction Assignment Submission
predictionassignmet<- function(){
prediction <- predict(model_rf_CV, test)
print(prediction)
answers <- as.vector(prediction)
pml_write_files(answers)
}
loadData()
cleanData()
splitdata()
fitmodel()
